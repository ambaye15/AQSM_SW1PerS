{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5a13f3-c060-478f-82ac-0059f60cd27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from Classification_experiments.classification_experiments import *\n",
    "from AQSM_SW1PerS.utils.paths import get_data_path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db570291-6c6b-4370-88e9-8628a938f62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = get_data_path(\"Periodicity_Scores\", \"exp1_PS/pose_exp1.csv\")\n",
    "\n",
    "binary_method = True\n",
    "PS1_scores = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17b0156-3010-4543-959d-dd85baf1ef69",
   "metadata": {},
   "source": [
    "# Experiment 1 - Startified Set Classification\n",
    "\n",
    "Using stratified random split for train/test/val sets. This will give good ingisht into feature importance and look into what the model stuggles with. The following hyperparameters were obtained via Bayesian Optimization with all sensors being required. We do this because when also exploring optimal sensor combinations, it was determined that all sensors are necessary for best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ca298b-fd1e-4bbd-ae74-fbee5a22478c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if binary_method:\n",
    "    class_names = ['None', 'SMM']\n",
    "    if PS1_scores:\n",
    "        best_params = {'n_estimators': 361, 'max_depth': 10, 'min_samples_split': 0.0001, 'min_samples_leaf': 0.0001, 'max_features': 'sqrt', 'class_weight': 'balanced_subsample', 'criterion': 'gini'}\n",
    "\n",
    "        accel_params =  {'n_estimators': 125, 'max_depth': 10, 'min_samples_split': 0.5, 'min_samples_leaf': 0.1073308009028807, 'max_features': 'sqrt', 'class_weight': 'balanced_subsample', 'criterion': 'entropy'}\n",
    "\n",
    "    else: \n",
    "        best_params =  {'n_estimators': 291, 'max_depth': 10, 'min_samples_split': 0.0001, 'min_samples_leaf': 0.0001, 'max_features': None, 'class_weight': 'balanced_subsample', 'criterion': 'entropy'}\n",
    "\n",
    "        accel_params =  {'n_estimators': 116, 'max_depth': 96, 'min_samples_split': 0.0001, 'min_samples_leaf': 0.048160194934634915, 'max_features': None, 'class_weight': 'balanced_subsample', 'criterion': 'log_loss'}\n",
    "\n",
    "else:\n",
    "    class_names = ['None', 'Rock', 'Flap', 'Flap-Rock']\n",
    "    if PS1_scores:\n",
    "        best_params =  {'n_estimators': 69, 'max_depth': 10, 'min_samples_split': 0.07027628488911168, 'min_samples_leaf': 0.20093207445139724, 'max_features': 'log2', 'class_weight': 'balanced', 'criterion': 'log_loss'}\n",
    "\n",
    "        accel_params =  {'n_estimators': 45, 'max_depth': 10, 'min_samples_split': 0.0001, 'min_samples_leaf': 0.0001, 'max_features': 'log2', 'class_weight': 'balanced', 'criterion': 'log_loss'}\n",
    "    else:\n",
    "        best_params = {'n_estimators': 500, 'max_depth': 11, 'min_samples_split': 0.0001, 'min_samples_leaf': 0.008792271867988076, 'max_features': 'sqrt', 'class_weight': 'balanced_subsample', 'criterion': 'log_loss'}\n",
    "\n",
    "        accel_params = {'n_estimators': 99, 'max_depth': 200, 'min_samples_split': 0.0001, 'min_samples_leaf': 0.0001, 'max_features': 'log2', 'class_weight': 'balanced_subsample', 'criterion': 'gini'}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d531b94-4c80-48ee-ac31-88508ab0481a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(data_file) \n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = test_train_val_split(df, 120)\n",
    "\n",
    "# Make absolute sure the only labels are {0,1,2,3}\n",
    "train_mask = y_train != -1\n",
    "test_mask = y_test != -1\n",
    "val_mask = y_val != -1\n",
    "\n",
    "X_train = X_train[train_mask]\n",
    "y_train = y_train[train_mask]\n",
    "\n",
    "X_test = X_test[test_mask]\n",
    "y_test = y_test[test_mask]\n",
    "\n",
    "X_val = X_val[val_mask]\n",
    "y_val = y_val[val_mask]\n",
    "\n",
    "num_total_features = len(X_train[0])\n",
    "\n",
    "num_feature_groups_10 = int(num_total_features/10)\n",
    "\n",
    "group_sizes = [10] * num_feature_groups_10\n",
    "\n",
    "if PS1_scores:\n",
    "    X_train = compress_features(X_train, group_sizes)\n",
    "    X_test = compress_features(X_test, group_sizes)\n",
    "\n",
    "X_train_resampled, y_train_resampled = train_class_oversampling(X_train, y_train, binary_method = binary_method)\n",
    "\n",
    "if binary_method:\n",
    "    y_train_resampled = (y_train_resampled != 0).astype(int)\n",
    "    y_test = (y_test != 0).astype(int)\n",
    "    y_val = (y_val != 0).astype(int)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99287f8-4e08-449d-a065-1fd8730e97a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = RandomForestClassifier(**accel_params, n_jobs=-1, random_state=42)\n",
    "\n",
    "model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "test_predictions = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f79230b-f9e6-459e-a1ed-3f6e13a8daa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_confusion_matrix(y_test, test_predictions, class_names, binary_method = binary_method, compressed = PS1_scores)\n",
    "\n",
    "report = classification_report(y_test, test_predictions, target_names=class_names, digits=2)\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce63e6eb-1b22-47ec-89b5-2e5698410720",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "feature_names = ['Head Pos', 'LW Pos', 'RW Pos', 'LS Pos', 'RS Pos', 'Chest Pos',\n",
    "                 'Head Accel', 'LW Accel', 'RW Accel', 'LS Accel', 'RS Accel', 'Chest Accel']\n",
    "\n",
    "# Compute importances\n",
    "importances = model.feature_importances_\n",
    "\n",
    "if not PS1_scores:\n",
    "    n_features_per_sensor = 10\n",
    "    sensor_importances = [\n",
    "        np.sum(importances[i * n_features_per_sensor:(i + 1) * n_features_per_sensor])\n",
    "        for i in range(len(feature_names))\n",
    "    ]\n",
    "    \n",
    "    sorted_idx = np.argsort(sensor_importances)[::-1]\n",
    "    sorted_importances = np.array(sensor_importances)[sorted_idx]\n",
    "    sorted_names = np.array(feature_names)[sorted_idx]\n",
    "else:\n",
    "    sorted_idx = np.argsort(importances)[::-1]\n",
    "    sorted_importances = np.array(importances)[sorted_idx]\n",
    "    sorted_names = np.array(feature_names)[sorted_idx]\n",
    "\n",
    "# Method label\n",
    "method_name = fr'$PS_1$' if PS1_scores else fr'$PS_{{10}}$'\n",
    "\n",
    "# --- Plotting ---\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "ax.bar(range(len(sorted_importances)), sorted_importances, align=\"center\")\n",
    "ax.set_xticks(range(len(sorted_names)))\n",
    "ax.set_xticklabels(sorted_names, rotation=90, fontsize=12)\n",
    "ax.set_title(f\"{method_name} Binary Model – Feature Importances\", fontsize=14)\n",
    "ax.tick_params(axis='y', labelsize=12)\n",
    "ax.set_ylabel(\"Importance\", fontsize=13)\n",
    "ax.set_xlabel(\"Feature\", fontsize=13)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f64d4b-3787-4b2b-bdf4-30e26d97cc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_auc_curve(model, X_test, y_test, binary=binary_method)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b222cf4-68a0-400a-95be-58780890a046",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_PR_curve(model, X_test, y_test, binary=binary_method, compressed = PS1_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7be0430-5cf5-434c-a533-f265b2bf1088",
   "metadata": {},
   "source": [
    "# Experiment 2 - Leave-One-Session-Out\n",
    "\n",
    "To enable closer comparison with established baselines in the field, the LOCO method can be adapted to leave a single session out rather than the data of an entire child. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0850102-92a1-419a-8784-e807a232a83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "leave_one_out_bayes(data_file, LOSO_method = 'Child', PS1 = True, binary_method = binary_method, plotCM = True,  plotPR = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49a7335-9df2-49fc-a01e-4a8ab687075c",
   "metadata": {},
   "source": [
    "# Experiment 3 - Leave-One-Child-Out\n",
    "\n",
    "To test the performance of the TDA features on truly unseen data, Leave-One-Child-Out (LOCO) was performed where the model is tested on the data of one child while the remaining children’s data is used for training and validation with Bayesian optimization used to find the near-optimal hyperparameters for the Random Forest Classifier. This method better reflects real-world deployment scenarios where models are applied to completely unseen individuals.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16c3d34-b881-42bf-b9c8-0bd67a2dd096",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "leave_one_out_bayes(data_file, LOSO_method = 'Child', PS1 = True, binary_method = binary_method, plotCM = True, plotPR = True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
