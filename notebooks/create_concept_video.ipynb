{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5014715b-2ef4-4600-b837-40a4e9de510d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import cv2\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from AQSM_SW1PerS.utils.data_processing import *\n",
    "from AQSM_SW1PerS.SW1PerS import *\n",
    "from AQSM_SW1PerS.utils.paths import get_data_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd32a734-af15-4b78-847a-066598abfd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from collections import deque\n",
    "\n",
    "class RealTimeRollingMedian:\n",
    "    def __init__(self, window_size):\n",
    "        self.window_size = window_size  # Size of the rolling window\n",
    "        self.window = deque()  # Deque to store the window of values\n",
    "\n",
    "    def update(self, value):\n",
    "        # Add new value to the rolling window\n",
    "        self.window.append(value)\n",
    "        if len(self.window) > self.window_size:\n",
    "            self.window.popleft()  # Remove the oldest value if the window exceeds the size\n",
    "\n",
    "        # Compute the rolling median excluding NaN values\n",
    "        valid_values = [v for v in self.window if not np.isnan(v)]\n",
    "        if valid_values:\n",
    "            return np.median(valid_values)\n",
    "        else:\n",
    "            return np.nan  # Return NaN if the window has only NaN values\n",
    "            \n",
    "\n",
    "def interpolate_and_detrend(t_x, t_y, t_vals, num_points):\n",
    "        \n",
    "    keypoint_x = t_x(t_vals)\n",
    "    keypoint_y = t_y(t_vals)\n",
    "    \n",
    "    keypoint_x = signal.detrend(keypoint_x)\n",
    "    keypoint_y = signal.detrend(keypoint_y)\n",
    "\n",
    "    f_x=CubicSpline(t_vals, keypoint_x)\n",
    "    f_y=CubicSpline(t_vals, keypoint_y)\n",
    "\n",
    "    cs = [f_x, f_y]\n",
    "\n",
    "    return keypoint_x, keypoint_y, cs\n",
    "    \n",
    "\n",
    "def create_concept_video(t_x, t_y, t_x_a, t_y_a, segments, fps, sensor = 'Chest'):\n",
    "\n",
    "    #Initalize rolling median period filter to ensure continuity of estimation\n",
    "    window_size = int(fps)\n",
    "    period_filter_spatial = RealTimeRollingMedian(window_size=window_size)\n",
    "    period_filter_accel = RealTimeRollingMedian(window_size=window_size)\n",
    "\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')  \n",
    "    out = cv2.VideoWriter(f'{sensor}_Plots.avi', fourcc, fps,  (2000, 800)) #Study 1: (352, 288), Study 2: (640,480)\n",
    "    \n",
    "    d = 23\n",
    "\n",
    "    prime_coeff = next_prime(2 * d)\n",
    "    method = 'PS1'\n",
    "    \n",
    "    for i,segment in enumerate(segments):\n",
    "        start=np.min(segment)\n",
    "        end=np.max(segment)\n",
    "        \n",
    "        num_points = 150\n",
    "        t_vals=np.linspace(start,end,num_points) \n",
    "\n",
    "        keypoint_x, keypoint_y, cs_spatial = interpolate_and_detrend(t_x, t_y, t_vals, num_points)\n",
    "        keypoint_x_accel, keypoint_y_accel, cs_accel = interpolate_and_detrend(t_x_a, t_y_a, t_vals, num_points)\n",
    "\n",
    "        sampling_rate = num_points / (end - start)\n",
    "\n",
    "        try:\n",
    "            period_spatial = estimate_period(keypoint_x, keypoint_y, sampling_rate)\n",
    "            smoothed_period_spatial = period_filter_spatial.update(period_spatial)\n",
    "            tau_spatial = smoothed_period_spatial / (d + 1)                         \n",
    "            SW_spatial = SW_cloud_nD(cs_spatial, t_vals, tau_spatial, d, 300, 2)\n",
    "            pca = PCA(n_components=2) \n",
    "            proj_2D_spatial = pca.fit_transform(SW_spatial)\n",
    "            \n",
    "            result_spatial = ripser(SW_spatial, coeff = prime_coeff, maxdim = 1) \n",
    "            diagrams_saptial = result_spatial['dgms']\n",
    "            dgm1_spatial = np.array(diagrams_saptial[1])\n",
    "            score_spatial = compute_PS(dgm1_spatial, method = method)\n",
    "        except:\n",
    "            diagrams_saptial = [np.array([[0.0, 0.0]]), np.empty((0, 2))]  # H0 and H1\n",
    "            score_spatial = [0]\n",
    "            proj_2D_spatial = np.array([[0.0, 0.0]]) \n",
    "\n",
    "        try:\n",
    "            period_accel = estimate_period(keypoint_x_accel, keypoint_y_accel, sampling_rate)\n",
    "            smoothed_period_accel = period_filter_accel.update(period_accel)\n",
    "            tau_accel = smoothed_period_accel / (d + 1)                         \n",
    "            SW_accel = SW_cloud_nD(cs_accel, t_vals, tau_accel, d, 300, 2)\n",
    "            pca = PCA(n_components=2) \n",
    "            proj_2D_accel = pca.fit_transform(SW_accel)\n",
    "            \n",
    "            result_accel = ripser(SW_accel, coeff = prime_coeff, maxdim = 1) \n",
    "            diagrams_accel = result_accel['dgms']\n",
    "            dgm1_accel = np.array(diagrams_accel[1])\n",
    "            score_accel = compute_PS(dgm1_accel, method = method)\n",
    "        except:\n",
    "            diagrams_accel = [np.array([[0.0, 0.0]]), np.empty((0, 2))]  # H0 and H1\n",
    "            score_accel = [0]\n",
    "            proj_2D_accel = np.array([[0.0, 0.0]]) \n",
    "\n",
    "            \n",
    "        fig = plt.figure(figsize=(20, 8))\n",
    "        \n",
    "        gs = GridSpec(2, 4, figure=fig)\n",
    "\n",
    "        ax1 = fig.add_subplot(gs[0,0])\n",
    "        ax1.plot(t_vals,keypoint_x,color='r',label = 'X')\n",
    "        ax1.plot(t_vals,keypoint_y,color='g',label = 'Y')\n",
    "        ax1.set_title(f'{sensor} Spatial Positions')\n",
    "        ax1.set_xlabel(\"Time\")\n",
    "        ax1.set_ylabel(\"Normalized Position\")\n",
    "        ax1.set_yticks([])\n",
    "        ax1.legend()\n",
    "\n",
    "        ax2 = fig.add_subplot(gs[0,1])\n",
    "        ax2.scatter(proj_2D_spatial[:,0], proj_2D_spatial[:,1], s=10, alpha=0.7, color='deepskyblue')\n",
    "        ax2.set_xticks([])\n",
    "        ax2.set_yticks([])\n",
    "        ax2.set_title(fr'PCA SW Point Cloud')\n",
    "\n",
    "        ax3 = fig.add_subplot(gs[0,2])\n",
    "        plot_diagrams(diagrams_saptial, plot_only=[1], xy_range=[0, 2, 0, 2], ax = ax3)\n",
    "        ax3.set_xticks([])\n",
    "        ax3.set_yticks([])\n",
    "        ax3.set_title(fr'Persistence Diagram')\n",
    "\n",
    "        ax4 = fig.add_subplot(gs[0,3])\n",
    "        ax4.bar(range(1), score_spatial, alpha=0.5)\n",
    "        ax4.set_title(fr'$PS_1$')\n",
    "        ax4.set_xlim(-0.5, 0.5)\n",
    "        ax4.set_ylim(0, 1)\n",
    "        ax4.set_xticks([])\n",
    "\n",
    "        ax5 = fig.add_subplot(gs[1,0])\n",
    "        ax5.plot(t_vals,keypoint_x_accel,color='r',label = 'X')\n",
    "        ax5.plot(t_vals,keypoint_y_accel,color='g',label = 'Y')\n",
    "        ax5.set_title(f'{sensor} Acceleration')\n",
    "        ax5.set_xlabel(\"Time\")\n",
    "        ax5.set_ylabel(\"Acceleration\")\n",
    "        ax5.set_yticks([])\n",
    "        ax5.legend()\n",
    "\n",
    "        ax6 = fig.add_subplot(gs[1,1])\n",
    "        ax6.scatter(proj_2D_accel[:,0], proj_2D_accel[:,1], s=10, alpha=0.7, color='darkcyan')\n",
    "        ax6.set_xticks([])\n",
    "        ax6.set_yticks([])\n",
    "        ax6.set_title(fr'PCA SW Point Cloud')\n",
    "\n",
    "        ax7 = fig.add_subplot(gs[1,2])\n",
    "        plot_diagrams(diagrams_accel, plot_only=[1], xy_range=[0, 2, 0, 2], ax = ax7)\n",
    "        ax7.set_xticks([])\n",
    "        ax7.set_yticks([])\n",
    "        ax7.set_title(fr'Persistence Diagram')\n",
    "\n",
    "        ax8 = fig.add_subplot(gs[1,3])\n",
    "        ax8.bar(range(1), score_accel, alpha=0.5)\n",
    "        ax8.set_title(fr'$PS_1$')\n",
    "        ax8.set_xlim(-0.5, 0.5)\n",
    "        ax8.set_ylim(0, 1)\n",
    "        ax8.set_xticks([])\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "        canvas = FigureCanvas(fig)  # Attach the canvas to the figure\n",
    "\n",
    "        # Now render the figure\n",
    "        canvas.draw()\n",
    "        \n",
    "        # Extract the RGB buffer from the *canvas* (not fig)\n",
    "        plot_image = np.frombuffer(canvas.buffer_rgba(), dtype='uint8')\n",
    "        plot_image = plot_image.reshape(fig.canvas.get_width_height()[::-1] + (4,))  # RGBA\n",
    "        \n",
    "        # Optionally convert RGBA to RGB\n",
    "        plot_image_rgb = plot_image[..., :3]\n",
    "        plot_image_bgr = cv2.cvtColor(plot_image_rgb, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        out.write(plot_image_bgr)\n",
    "        cv2.imshow('Plots',plot_image_bgr)\n",
    "        \n",
    "        cv2.waitKey(1)\n",
    "        # Close Matplotlib plot to avoid memory issues\n",
    "        plt.close(fig)\n",
    "        plt.close('all')\n",
    "\n",
    "        if start >= 40:\n",
    "            break\n",
    "\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ec2a961-9492-4077-bf7f-1c5ad08082f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pkl_file = get_data_path(\"dataset.pkl\")\n",
    "data = open_pickle(pkl_file)\n",
    "\n",
    "entry = data[13] \n",
    "fps, frame_times, segments, annotated_segments = segment_video(entry, 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "341b09a0-c78d-4101-8d3d-ea0c6b5d3a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "head = extract_keypoints(entry, 0, frame_times, fps)\n",
    "lshoulder = extract_keypoints(entry, 11, frame_times, fps)\n",
    "rshoulder = extract_keypoints(entry, 12, frame_times, fps)\n",
    "rwrist = extract_keypoints(entry, 16, frame_times, fps, do_wrists=True, elbow_index=14, shoulder_index=12)\n",
    "lwrist = extract_keypoints(entry, 15, frame_times, fps, do_wrists=True, elbow_index=13, shoulder_index=11)\n",
    "\n",
    "chest = getChest(head, lshoulder, rshoulder)\n",
    "\n",
    "lshoulder_accel = getAccel(lshoulder,fps)\n",
    "rshoulder_accel = getAccel(rshoulder,fps)\n",
    "\n",
    "rwrist_accel = getAccel(rwrist,fps)\n",
    "lwrist_accel = getAccel(lwrist,fps)\n",
    "\n",
    "head_accel = getAccel(head,fps)\n",
    "chest_accel = getAccel(chest,fps)\n",
    "\n",
    "'''\n",
    "Turn Keypoints into Spline Representation for the Main Algorithm to Interpolate Values\n",
    "'''\n",
    "\n",
    "#Raw keypoint positions\n",
    "\n",
    "h_x, h_y = CubicSpline(frame_times,head[:,0]), CubicSpline(frame_times,head[:,1])\n",
    "\n",
    "r_x, r_y = CubicSpline(frame_times,rwrist[:,0]), CubicSpline(frame_times,rwrist[:,1])\n",
    "\n",
    "l_x, l_y = CubicSpline(frame_times,lwrist[:,0]), CubicSpline(frame_times,lwrist[:,1])\n",
    "\n",
    "rs_x, rs_y = CubicSpline(frame_times,rshoulder[:,0]), CubicSpline(frame_times,rshoulder[:,1])\n",
    "\n",
    "ls_x, ls_y = CubicSpline(frame_times,lshoulder[:,0]), CubicSpline(frame_times,lshoulder[:,1])\n",
    "\n",
    "c_x, c_y = CubicSpline(frame_times,chest[:,0]), CubicSpline(frame_times,chest[:,1])\n",
    "\n",
    "#Acceleration representation of keypoint movement\n",
    "\n",
    "h_x_a, h_y_a = CubicSpline(frame_times,head_accel[:,0]), CubicSpline(frame_times,head_accel[:,1])\n",
    "\n",
    "r_x_a, r_y_a = CubicSpline(frame_times,rwrist_accel[:,0]), CubicSpline(frame_times,rwrist_accel[:,1])\n",
    "\n",
    "l_x_a, l_y_a = CubicSpline(frame_times,lwrist_accel[:,0]), CubicSpline(frame_times,lwrist_accel[:,1])\n",
    "\n",
    "rs_x_a, rs_y_a = CubicSpline(frame_times,rshoulder_accel[:,0]), CubicSpline(frame_times,rshoulder_accel[:,1])\n",
    "\n",
    "ls_x_a, ls_y_a = CubicSpline(frame_times,lshoulder_accel[:,0]), CubicSpline(frame_times,lshoulder_accel[:,1])\n",
    "\n",
    "c_x_a, c_y_a = CubicSpline(frame_times,chest_accel[:,0]), CubicSpline(frame_times,chest_accel[:,1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0af8894-3675-4dbe-ba55-ae68d54b0754",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sensor = \"Chest\"\n",
    "segment_indices = create_concept_video(c_x, c_y, c_x_a, c_y_a, segments, fps, sensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "565d1e0b-007a-417b-9b3e-982cb69bbbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mediapipe_video = data_file = get_data_path(\"MPVideos\", \"004-01-17-08_0_study1_mp.avi\")\n",
    "\n",
    "#Create full concept video with with MediaPipe video and plots\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter(f'concept_video_final.avi', fourcc, fps, (1600, 800))\n",
    "\n",
    "cap1 = cv2.VideoCapture(mediapipe_video)\n",
    "cap2 = cv2.VideoCapture(f'{sensor}_Plots.avi')\n",
    "\n",
    "segment_index = 0\n",
    "frame_index = 0\n",
    "\n",
    "y_class = entry['annotations']\n",
    "\n",
    "while cap1.isOpened():\n",
    "    \n",
    "    ret1,frame1=cap1.read()\n",
    "    if not ret1:\n",
    "        break\n",
    "    \n",
    "    frame1 = cv2.resize(frame1, (1600, 800))\n",
    "    # Add text to the MediaPipe frame\n",
    "    if y_class[frame_index] == 0:\n",
    "        cv2.putText(frame1, f'Annotation: No Stereotypy', (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 1, cv2.LINE_AA)\n",
    "    elif y_class[frame_index] == 1:\n",
    "        cv2.putText(frame1, f'Annotation: Rocking', (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 1, cv2.LINE_AA)\n",
    "    elif y_class[frame_index] == 2:\n",
    "        cv2.putText(frame1, f'Annotation: Flapping', (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 1, cv2.LINE_AA)\n",
    "    else:\n",
    "        cv2.putText(frame1, f'Annotation: Flap-Rock', (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 1, cv2.LINE_AA)\n",
    "    frame_index += 1\n",
    "    current_frame = cap1.get(cv2.CAP_PROP_POS_FRAMES)\n",
    "    current_time = current_frame / fps\n",
    "    if current_time <= np.max(segments[segment_index]):\n",
    "        cap2.set(cv2.CAP_PROP_POS_FRAMES, segment_index)\n",
    "    else: \n",
    "        segment_index+=1\n",
    "        cap2.set(cv2.CAP_PROP_POS_FRAMES, segment_index)\n",
    "\n",
    "    counter=0\n",
    "    while counter==0:\n",
    "        ret2, frame2 = cap2.read()\n",
    "\n",
    "        if not ret2:\n",
    "            break \n",
    "            \n",
    "        frame2_resized = cv2.resize(frame2, (1600, 800))\n",
    "        combined_plots = frame2_resized\n",
    "        \n",
    "        combined_frame = cv2.hconcat([frame1, combined_plots])\n",
    "        \n",
    "        combined_frame = cv2.resize(combined_frame, (1600, 800))\n",
    "        \n",
    "        out.write(combined_frame)\n",
    "        cv2.imshow('Combined Video', combined_frame)\n",
    "        \n",
    "        counter+=1\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "            \n",
    "    if segment_index==segment_indices:\n",
    "        break\n",
    "        \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "cap1.release()\n",
    "cap2.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
