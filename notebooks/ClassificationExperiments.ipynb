{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3001db85-4415-4cb0-b886-74631a2929ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "from classification_tools.experiments import *\n",
    "from AQSM_SW1PerS.utils.paths import get_data_path\n",
    "\n",
    "#Visualizations\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, roc_curve, auc, precision_recall_curve, average_precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e431ec0-f2ef-434c-8560-59fb69440a53",
   "metadata": {},
   "source": [
    "# Running Experiments\n",
    "\n",
    "Below we use the `ClassificationExperiments` class in `classification_tools/experiments` to run and evaluate the different classification experiments presented in the paper. The class provides a unified interface for:\n",
    "\n",
    "- Loading preprocessed feature sets from `scores_dir`(the different directories are located in the Dataset directory)  \n",
    "- Splitting data according to the chosen experimental design (e.g., Stratified, LOCO, LOSO)  \n",
    "- Optionally applying feature selection and hyperparameter optimization using Bayesian optimization\n",
    "- Training and evaluating a Random Forest classifier\n",
    "\n",
    "\n",
    "The parameters one must choose for `ClassificationExperiments` are as follows:\n",
    "\n",
    "- `scores_dir` (str): directory where the `.csv` files for a given experiment are located.\n",
    "- `experiment` (str): experimental design (Default = 'stratified'). May also choose 'LOSO' (Leave-one-Session-Out) or 'LOCO' (Leave-one-Individual-Out), must manually add more if desired. When set to 'stratified', it will return \n",
    "- `input_modality` (str): either 'accelerometer' or 'pose' (Default = 'pose').\n",
    "- `method` (str): topologically-derived periodicity score method, either 'PS1' or 'PS10' (Default = 'PS1').\n",
    "- `binary` (bool): perform binary if set True, multiclass if set to False Default = True).\n",
    "- `include_freq` (bool): Should only be toggled True for accelerometer data unless high frame-rate videos are used. Supplemental feature to boost classification accuracy for accelerometer data (Default = False).\n",
    "- `optimize` (bool): If True, then will find near-optimal hyperparameters using Bayesian optimization (Default = False).\n",
    "- `load_params` (dict): Optionally load pre-optimized hyperparameters presented above (Default = None). Will be used if optimize = False.\n",
    "- `optimize_feature_space` (bool): Along with hyperparameters, also optimize the selection of features (e.g. sensors or landmarks) used (Default = False).\n",
    "- `random_state` (int): For reproducibility (Default= 42).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206aadcc-0c7b-4b00-a70a-b016c30d582e",
   "metadata": {},
   "source": [
    "## Example: Stratified Classification of Accelerometer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0913f1-aded-41d0-9e32-72be7c6ab321",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change as desired for use\n",
    "\n",
    "scores_dir = get_data_path('experiments/experiment_1/accelerometer_exp1')\n",
    "experiment = 'stratified'\n",
    "input_modality = 'accelerometer'\n",
    "method = 'PS1'\n",
    "binary = True\n",
    "include_freq = False\n",
    "optimize = True\n",
    "params = False\n",
    "optimize_feature_space = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c4999f-3396-441c-b5ba-9fa971deba1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example: Stratified classification (Experiment 1) using above parameters and scores_dir\n",
    "\n",
    "ClassExp = ClassificationExperiments(scores_dir, \n",
    "                                     experiment = experiment, \n",
    "                                     input_modality = input_modality, \n",
    "                                     method = method, \n",
    "                                     binary = binary,\n",
    "                                     include_freq = include_freq,\n",
    "                                     optimize = optimize,\n",
    "                                     load_params = params,\n",
    "                                     optimize_feature_space = optimize_feature_space,\n",
    "                                     )\n",
    "\n",
    "\n",
    "ClassExp.run_classification_experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908c2e63-813b-4b92-a575-66d75495b1fc",
   "metadata": {},
   "source": [
    "## Example: LOSO Classification of Pose data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17595302-cd75-4ecb-9f1b-93e83526074f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change as desired for use\n",
    "\n",
    "scores_dir = get_data_path('experiments/experiment_234/pose_exp234')\n",
    "experiment = 'LOSO'\n",
    "input_modality = 'pose'\n",
    "method = 'PS10'\n",
    "binary = True\n",
    "include_freq = False\n",
    "optimize = True\n",
    "params = False\n",
    "optimize_feature_space = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27c2513-1b1f-4ac8-97d6-19bd2ffd646d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example: Stratified classification (Experiment 1) using above parameters and scores_dir\n",
    "\n",
    "ClassExp = ClassificationExperiments(scores_dir, \n",
    "                                     experiment = experiment, \n",
    "                                     input_modality = input_modality, \n",
    "                                     method = method, \n",
    "                                     binary = binary,\n",
    "                                     include_freq = include_freq,\n",
    "                                     optimize = optimize,\n",
    "                                     load_params = params,\n",
    "                                     optimize_feature_space = optimize_feature_space,\n",
    "                                     )\n",
    "\n",
    "\n",
    "ClassExp.run_classification_experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4beb8c95-5911-4450-b268-240b45e6b313",
   "metadata": {},
   "source": [
    "## Example: LOCO Classification of Accelerometer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79cde26-c855-4cd3-a1d7-b2583224b17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change as desired for use\n",
    "scores_dir = get_data_path('experiments/experiment_234/accelerometer_exp234')\n",
    "experiment = 'LOSO'\n",
    "input_modality = 'accelerometer'\n",
    "method = 'PS1'\n",
    "binary = True\n",
    "include_freq = True\n",
    "optimize = True\n",
    "params = False\n",
    "optimize_feature_space = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014ab403-e64b-4078-adbc-6d486e9c0f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example: Stratified classification (Experiment 1) using above parameters and scores_dir\n",
    "\n",
    "ClassExp = ClassificationExperiments(scores_dir, \n",
    "                                     experiment = experiment, \n",
    "                                     input_modality = input_modality, \n",
    "                                     method = method, \n",
    "                                     binary = binary,\n",
    "                                     include_freq = include_freq,\n",
    "                                     optimize = optimize,\n",
    "                                     load_params = params,\n",
    "                                     optimize_feature_space = optimize_feature_space,\n",
    "                                     )\n",
    "\n",
    "\n",
    "ClassExp.run_classification_experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bd21e3-cebd-41e3-9f32-6af073d7a9e4",
   "metadata": {},
   "source": [
    "# Visualizations\n",
    "\n",
    "Below is how we can use the class to recreate the visualizations presented in the paper. We call two initializations of `ClassificationExperiments` to compare $PS_1$ and $PS_{10}$ with the above parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55a21cc-b5c3-4c83-a5fc-3187cbf4bc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scores_dir = get_data_path('experiments/experiment_1/pose_exp1')\n",
    "experiment = 'stratified'\n",
    "input_modality = 'pose'\n",
    "binary = True\n",
    "include_freq = False\n",
    "optimize = True\n",
    "optimize_feature_space = True\n",
    "return_model = True\n",
    "\n",
    "\n",
    "ClassExp_1 = ClassificationExperiments(scores_dir, \n",
    "                                     experiment = experiment, \n",
    "                                     input_modality = input_modality, \n",
    "                                     method = 'PS1', \n",
    "                                     binary = binary,\n",
    "                                     include_freq = include_freq,\n",
    "                                     optimize = optimize,\n",
    "                                     load_params = None,\n",
    "                                     optimize_feature_space = optimize_feature_space,\n",
    "                                     return_model = return_model)\n",
    "\n",
    "\n",
    "ClassExp_1.run_classification_experiment()\n",
    "\n",
    "model_1 = ClassExp_1.model\n",
    "\n",
    "ClassExp_10 = ClassificationExperiments(scores_dir, \n",
    "                                     experiment = experiment, \n",
    "                                     input_modality = input_modality, \n",
    "                                     method = 'PS10', \n",
    "                                     binary = binary,\n",
    "                                     include_freq = include_freq,\n",
    "                                     optimize = optimize,\n",
    "                                     load_params = None,\n",
    "                                     optimize_feature_space = optimize_feature_space,\n",
    "                                     return_model = return_model)\n",
    "\n",
    "\n",
    "ClassExp_10.run_classification_experiment()\n",
    "model_10 = ClassExp_10.model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b735ce-b584-48d7-8ea3-ea39806aebc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_confusion_matrices(class1, \n",
    "                               class2, \n",
    "                               plot1_title = fr\"$PS_{1}$ Pose Multi.\",\n",
    "                               plot2_title = r\"$PS_{10}$ Pose Multi.\",\n",
    "                               save_fig = False,\n",
    "                               fig_path = 'pose_multi_cm.pdf'):\n",
    "    \n",
    "    # Compute confusion matrices\n",
    "    cm1 = confusion_matrix(class1.y_test, class1.test_predictions)\n",
    "    cm2 = confusion_matrix(class2.y_test, class2.test_predictions)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 10), constrained_layout=True)\n",
    "    \n",
    "    # Panel (a)\n",
    "    disp1 = ConfusionMatrixDisplay(confusion_matrix=cm1, display_labels=class1.class_names)\n",
    "    disp1.plot(cmap=\"Blues\", xticks_rotation=45, ax=axes[0], colorbar=False)\n",
    "    axes[0].set_title(plot1_title)\n",
    "    axes[0].text(-0.1, 1.02, \"(a)\", transform=axes[0].transAxes,\n",
    "                 ha=\"left\", va=\"bottom\", fontweight=\"bold\")\n",
    "    \n",
    "    # Panel (b)\n",
    "    disp2 = ConfusionMatrixDisplay(confusion_matrix=cm2, display_labels=class1.class_names)\n",
    "    disp2.plot(cmap=\"Blues\", xticks_rotation=45, ax=axes[1], colorbar=False)\n",
    "    axes[1].set_title(plot2_title)\n",
    "    axes[1].text(-0.1, 1.02, \"(b)\", transform=axes[1].transAxes,\n",
    "                 ha=\"left\", va=\"bottom\", fontweight=\"bold\")\n",
    "    \n",
    "    plt.show()\n",
    "    if save_fig:\n",
    "        fig.savefig(fig_path, bbox_inches=\"tight\", dpi=300)\n",
    "\n",
    "\n",
    "def compare_pr_curves(class1,\n",
    "                      model1,\n",
    "                      class2,\n",
    "                      model2,\n",
    "                      binary = True,\n",
    "                      plot1_title = fr\"Pose Precision-Recall Curve Multi. ($PS_{1}$)\",\n",
    "                      plot2_title = r\"Pose Precision-Recall Curve Multi. ($PS_{10}$)\",\n",
    "                      save_fig = False,\n",
    "                      fig_path = 'pose_multi_pr.pdf'):\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 6), constrained_layout=True)\n",
    "    y_score1 = model1.predict_proba(class1.X_test)\n",
    "    y_score2 = model2.predict_proba(class2.X_test)\n",
    "\n",
    "    if binary:\n",
    "        y_score_pos1 = y_score1[:, 1]\n",
    "        precision1, recall1, _ = precision_recall_curve(class1.y_test, y_score_pos1)\n",
    "        avg_precision1 = average_precision_score(class1.y_test, y_score_pos1)\n",
    "\n",
    "        y_score_pos2 = y_score2[:, 1]\n",
    "        precision2, recall2, _ = precision_recall_curve(class2.y_test, y_score_pos2)\n",
    "        avg_precision2 = average_precision_score(class2.y_test, y_score_pos2)\n",
    "\n",
    "        axes[0].plot(recall1, precision1, lw=2, label=f'AP = {avg_precision1:.2f}')\n",
    "        axes[0].set_xlabel('Recall')\n",
    "        axes[0].set_ylabel('Precision')\n",
    "        axes[0].set_title(plot1_title)\n",
    "        axes[0].legend(loc='lower left')\n",
    "        axes[0].grid(True)\n",
    "        axes[0].set_ylim([0.0, 1.05])\n",
    "        axes[0].set_xlim([0.0, 1.0])\n",
    "        axes[0].text(-0.1, 1.02, \"(a)\", transform=axes[0].transAxes,\n",
    "                     ha=\"left\", va=\"bottom\", fontweight=\"bold\")\n",
    "\n",
    "        axes[1].plot(recall2, precision2, lw=2, label=f'AP = {avg_precision2:.2f}')\n",
    "        axes[1].set_xlabel('Recall')\n",
    "        axes[1].set_ylabel('Precision')\n",
    "        axes[1].set_title(plot2_title)\n",
    "        axes[1].legend(loc='lower left')\n",
    "        axes[1].grid(True)\n",
    "        axes[1].set_ylim([0.0, 1.05])\n",
    "        axes[1].set_xlim([0.0, 1.0])\n",
    "        axes[1].text(-0.1, 1.02, \"(b)\", transform=axes[1].transAxes,\n",
    "                     ha=\"left\", va=\"bottom\", fontweight=\"bold\")\n",
    "        \n",
    "        plt.show()\n",
    "        if save_fig:\n",
    "            fig.savefig(fig_path, bbox_inches=\"tight\", dpi=300)\n",
    "\n",
    "    else:\n",
    "        class_names = ['None', 'Rock', 'Flap', 'Flap-Rock']\n",
    "        classes = np.array([0, 1, 2, 3])\n",
    "        \n",
    "        y_test_bin1 = label_binarize(class1.y_test, classes=classes)\n",
    "        precision1 = dict()\n",
    "        recall1 = dict()\n",
    "        avg_precision1 = dict()\n",
    "        for i in range(len(classes)):\n",
    "            precision1[i], recall1[i], _ = precision_recall_curve(y_test_bin1[:, i], y_score1[:, i])\n",
    "            avg_precision1[i] = average_precision_score(y_test_bin1[:, i], y_score1[:, i])\n",
    "\n",
    "        y_test_bin2 = label_binarize(class2.y_test, classes=classes)\n",
    "        precision2 = dict()\n",
    "        recall2 = dict()\n",
    "        avg_precision2 = dict()\n",
    "        for i in range(len(classes)):\n",
    "            precision2[i], recall2[i], _ = precision_recall_curve(y_test_bin2[:, i], y_score2[:, i])\n",
    "            avg_precision2[i] = average_precision_score(y_test_bin2[:, i], y_score2[:, i])\n",
    "            \n",
    "        for i in range(len(classes)):\n",
    "            axes[0].plot(recall1[i], precision1[i], lw=2, label=f'{class_names[i]} (AP = {avg_precision1[i]:.2f})')\n",
    "        axes[0].set_xlabel('Recall')\n",
    "        axes[0].set_ylabel('Precision')\n",
    "        axes[0].set_title(plot1_title)\n",
    "        axes[0].legend(loc=\"lower left\")\n",
    "        axes[0].grid(True)\n",
    "        axes[0].set_ylim([0.0, 1.05])\n",
    "        axes[0].set_xlim([0.0, 1.0])\n",
    "        axes[0].text(-0.1, 1.02, \"(a)\", transform=axes[0].transAxes,\n",
    "                     ha=\"left\", va=\"bottom\", fontweight=\"bold\")\n",
    "\n",
    "        for i in range(len(classes)):\n",
    "            axes[1].plot(recall2[i], precision2[i], lw=2, label=f'{class_names[i]} (AP = {avg_precision2[i]:.2f})')\n",
    "        axes[1].set_xlabel('Recall')\n",
    "        axes[1].set_ylabel('Precision')\n",
    "        axes[1].set_title(plot2_title)\n",
    "        axes[1].legend(loc=\"lower left\")\n",
    "        axes[1].grid(True)\n",
    "        axes[1].set_ylim([0.0, 1.05])\n",
    "        axes[1].set_xlim([0.0, 1.0])\n",
    "        axes[1].text(-0.1, 1.02, \"(b)\", transform=axes[1].transAxes,\n",
    "                     ha=\"left\", va=\"bottom\", fontweight=\"bold\")\n",
    "        plt.show()\n",
    "        if save_fig:\n",
    "            fig.savefig(fig_path, bbox_inches=\"tight\", dpi=300)\n",
    "\n",
    "def sum_importances_per_sensor(importances, sensors, feature_names=None, n_per=10):\n",
    "    if feature_names is None:\n",
    "        assert len(importances) == len(sensors) * n_per\n",
    "        return np.array([\n",
    "            importances[i*n_per:(i+1)*n_per].sum()\n",
    "        for i in range(len(sensors))])\n",
    "    else:\n",
    "        prefix = [n.split(\"_\", 1)[0] for n in feature_names]\n",
    "        sums = {s: 0.0 for s in sensors}\n",
    "        for imp, pref in zip(importances, prefix):\n",
    "            if pref in sums:\n",
    "                sums[pref] += imp\n",
    "        return np.array([sums[s] for s in sensors])\n",
    "\n",
    "\n",
    "def compare_feature_importances(class1, \n",
    "                                model1,\n",
    "                                class2,\n",
    "                                model2,\n",
    "                                plot1_title = fr\"Pose $PS_{1}$ Binary - Feature Importances\",\n",
    "                                plot2_title = r\"Pose $PS_{10}$ Binary - Feature Importances\",\n",
    "                                save_fig = False,\n",
    "                                fig_path = 'pose_feature_importances.pdf'):\n",
    "\n",
    "        \n",
    "    if class1.input_modality == 'accelerometer':\n",
    "        sensors = [\"Torso\", \"LWrist\", \"RWrist\"]\n",
    "        feature_names_10 = [f\"Torso_{i}\" for i in range(1, 11)] + [f\"LWrist_{i}\" for i in range(1, 11)] + [f\"RWrist_{i}\" for i in range(1, 11)]\n",
    "    else:\n",
    "        sensors = [\"Head\", \"RWrist\", \"LWrist\", \"RShoulder\", \"LShoulder\", \"Chest\", \"Head_Accel\", \"RWrist_Accel\", \"LWrist_Accel\", \"RShoulder_Accel\", \"LShoulder_Accel\", \"Chest_Accel\"]\n",
    "        sensor_names = [\"Head\", \"RWrist\", \"L Wrist\", \"R Shoulder\", \"L Shoulder\", \"Chest\", \"Head Accel\", \"R Wrist Accel\", \"L Wrist Accel\", \"R Shoulder Accel\", \"L Shoulder Accel\", \"Chest Accel\"]\n",
    "\n",
    "        feature_names_10 = [f\"Head_{i}\" for i in range(1, 11)] + \\\n",
    "                [f\"RWrist_{i}\" for i in range(1, 11)] + \\\n",
    "                [f\"LWrist_{i}\" for i in range(1, 11)] + \\\n",
    "                [f\"RShoulder_{i}\" for i in range(1, 11)] + \\\n",
    "                [f\"LShoulder_{i}\" for i in range(1, 11)] + \\\n",
    "                [f\"Chest_{i}\" for i in range(1, 11)] + \\\n",
    "                [f\"Head_Accel_{i}\" for i in range(1, 11)] + \\\n",
    "                [f\"RWrist_Accel_{i}\" for i in range(1, 11)] + \\\n",
    "                [f\"LWrist_Accel_{i}\" for i in range(1, 11)] + \\\n",
    "                [f\"RShoulder_Accel_{i}\" for i in range(1, 11)] + \\\n",
    "                [f\"LShoulder_Accel_{i}\" for i in range(1, 11)] + \\\n",
    "                [f\"Chest_Accel_{i}\" for i in range(1, 11)]\n",
    "\n",
    "    if class1.optimize_feature_space:\n",
    "        feature_mask1 = class1.best_feature_selection\n",
    "        sensors1 = [s for s, keep in zip(sensor_names, feature_mask1) if keep]\n",
    "        \n",
    "    if class2.optimize_feature_space:\n",
    "        feature_mask2 = class2.best_feature_selection\n",
    "        sensors2 = [s for s, keep in zip(sensors, feature_mask2) if keep]\n",
    "        sensor_names2 =  [s for s, keep in zip(sensor_names, feature_mask2) if keep]\n",
    "        feature_names_10 = [f for f in feature_names_10 if any(f.startswith(p) for p in sensors2)]\n",
    "\n",
    "    imp1 = model1.feature_importances_    \n",
    "    \n",
    "    imp2_sum = sum_importances_per_sensor(\n",
    "        model2.feature_importances_, sensors2, feature_names=feature_names_10, n_per=10\n",
    "    )\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(20, 7), constrained_layout=True, sharey=False)\n",
    "\n",
    "    # (a) model1\n",
    "    axes[0].bar(np.arange(len(sensors1)), imp1)\n",
    "    axes[0].set_xticks(np.arange(len(sensors1)))\n",
    "    axes[0].set_xticklabels(sensors1, rotation=45)\n",
    "    axes[0].set_ylabel(\"Importances\", family = \"Times New Roman\", fontsize = 15)\n",
    "    axes[0].set_title(plot1_title, family = \"Times New Roman\", fontsize = 20)\n",
    "    axes[0].text(-0.05, 1.02, \"(a)\", transform=axes[0].transAxes,\n",
    "                 ha=\"left\", va=\"bottom\", fontweight=\"bold\")\n",
    "    \n",
    "    # (b) model2\n",
    "    axes[1].bar(np.arange(len(sensors2)), imp2_sum)\n",
    "    axes[1].set_xticks(np.arange(len(sensors2)))\n",
    "    axes[1].set_xticklabels(sensor_names2, rotation=45)\n",
    "    axes[1].set_ylabel(\"Summed Importances\", family = \"Times New Roman\", fontsize = 15)\n",
    "    \n",
    "    axes[1].set_title(plot2_title,  family = \"Times New Roman\", fontsize = 20)\n",
    "    axes[1].text(-0.05, 1.02, \"(b)\", transform=axes[1].transAxes,\n",
    "                 ha=\"left\", va=\"bottom\", fontweight=\"bold\")\n",
    "    \n",
    "    plt.show()\n",
    "    if save_fig:\n",
    "        fig.savefig(fig_path, bbox_inches=\"tight\", dpi=300)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3c1e54-c510-44ea-bb69-5a0bb94c9c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_confusion_matrices(ClassExp_1, ClassExp_10, save_fig = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836402d6-d1af-4c41-840f-60a8c6896add",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_pr_curves(ClassExp_1, model_1, ClassExp_10, model_10, binary = binary, save_fig = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ad5f30-3496-46bd-99a4-616a0a8e8155",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_feature_importances(ClassExp_1, model_1, ClassExp_10, model_10, save_fig = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbb14c8-68b7-47ff-a172-31b66206b561",
   "metadata": {},
   "source": [
    "# Visualizations - Feature Space\n",
    "\n",
    "The following is used to create the UMAP visualizations presented in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3394a981-a4ee-40d0-bfd5-ac138c8f9a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap.umap_ as umap\n",
    "from sklearn.decomposition import PCA\n",
    "import plotly.express as px\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26132ee5-c9ec-43ac-b084-324d348be80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explained_variance_plots(X_features):\n",
    "    '''\n",
    "    Shows the minimum number of dimensions in the feature space needed to explain 95% of the variance\n",
    "    '''\n",
    "    pca = PCA(n_components=min(X_features.shape[1], 50)) \n",
    "    X_pca = pca.fit_transform(X_features)\n",
    "    \n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.plot(np.cumsum(pca.explained_variance_ratio_), marker='o')\n",
    "    plt.axhline(y=0.95, color='r', linestyle='--', label=\"95% Variance Threshold\")\n",
    "    plt.xlabel(\"Number of Components\")\n",
    "    plt.ylabel(\"Cumulative Explained Variance\")\n",
    "    plt.title(\"PCA Explained Variance\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_interactive(df_umap_tda, save_html=False, color_by_anno=True, output_name = 'anno_tda'):\n",
    "\n",
    "    if color_by_anno:\n",
    "        color = df_umap_tda['Annotations'].astype(str)\n",
    "    else:\n",
    "        color = df_umap_tda['PersonID'].astype(str)\n",
    "\n",
    "    fig = px.scatter_3d(df_umap_tda, x='UMAP1', y='UMAP2', z='UMAP3', \n",
    "                     color=color,  \n",
    "                     title=\"Interactive TDA Features UMAP\",\n",
    "                     opacity=0.2)\n",
    "    fig.update_traces(marker=dict(size=2)) \n",
    "    fig.show()\n",
    "    if save_html:\n",
    "        fig.write_html(f'{output_name}.html')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7013d421-8ad9-45e0-8150-b04fd95ee86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change as desired for use\n",
    "\n",
    "scores_dir = get_data_path('')\n",
    "input_modality = 'accelerometer'\n",
    "method = 'PS1'\n",
    "include_freq = True\n",
    "\n",
    "Feature_extraction = ClassificationExperiments(scores_dir, input_modality = input_modality, method = method, include_freq = include_freq)\n",
    "\n",
    "Feature_extraction.load_data()\n",
    "X_features = Feature_extraction.features\n",
    "\n",
    "explained_variance_plots(X_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f260e2dd-8b18-493f-9c60-a76b305b42b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "umap_reducer = umap.UMAP(n_components=3, random_state=42, n_jobs = -1)\n",
    "X_umap = umap_reducer.fit_transform(X_features)\n",
    "\n",
    "df_umap = pd.DataFrame(X_umap, columns=['UMAP1', 'UMAP2', 'UMAP3'])\n",
    "\n",
    "df_umap['PersonID'] = Feature_extraction.person_ids\n",
    "df_umap['Annotations'] = Feature_extraction.annotations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a4ffdc-d584-4067-a7fe-53f64a052810",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_interactive(df_umap, color_by_anno = True, save_html=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f28159c-a82e-47d6-ae58-4ddb476dafd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "def rgb_string_to_tuple(rgb_string):\n",
    "    parts = rgb_string.strip('rgb()').split(',')\n",
    "    return tuple(int(p) / 255 for p in parts)\n",
    "\n",
    "plotly_safe_rgb = px.colors.qualitative.Safe\n",
    "plotly_safe_mpl = [rgb_string_to_tuple(c) for c in plotly_safe_rgb]\n",
    "\n",
    "label_map = {\n",
    "    0: 'None',\n",
    "    1: 'Rock',\n",
    "    2: 'Flap',\n",
    "    3: 'Flap Rock'\n",
    "}\n",
    "label_order = ['None', 'Rock', 'Flap', 'Flap Rock']\n",
    "color_sequence = ['#000000', '#E69F00', '#56B4E9', '#009E73']\n",
    "cat_type = CategoricalDtype(categories=label_order, ordered=True)\n",
    "\n",
    "# --- Subsample Once ---\n",
    "df_sampled = df_umap.groupby('PersonID').apply(lambda x: x.sample(frac=0.3)).reset_index(drop=True)\n",
    "\n",
    "# Add necessary columns\n",
    "df_sampled['PersonID'] = df_sampled['PersonID'].astype(str)\n",
    "df_sampled['Label'] = df_sampled['Annotations'].map(label_map).astype(cat_type)\n",
    "\n",
    "# Create color maps\n",
    "unique_pids = sorted(df_sampled['PersonID'].unique())\n",
    "color_map_pid = dict(zip(unique_pids, plotly_safe_mpl[:len(unique_pids)]))\n",
    "color_map_label = dict(zip(label_order, color_sequence))\n",
    "\n",
    "# --- Create Side-by-Side Figure ---\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Panel (a): Colored by Child\n",
    "sns.scatterplot(\n",
    "    data=df_sampled,\n",
    "    x='UMAP3',\n",
    "    y='UMAP2',\n",
    "    hue='PersonID',\n",
    "    palette=color_map_pid,\n",
    "    s=30,\n",
    "    alpha=0.6,\n",
    "    linewidth=0,\n",
    "    ax=ax1\n",
    ")\n",
    "ax1.set_title(r\"2D UMAP Accelerometer Feature Space $PS_{1}$ – Colored by Child\", fontsize=14, family=\"Times New Roman\")\n",
    "ax1.set_xlabel(\"UMAP2\", fontsize=12, family=\"Times New Roman\")\n",
    "ax1.set_ylabel(\"UMAP3\", fontsize=12, family=\"Times New Roman\")\n",
    "ax1.set_xticks([]); ax1.set_yticks([])\n",
    "ax1.text(-0.1, 1.05, \"(a)\", transform=ax1.transAxes, fontsize=14, fontweight=\"bold\", family=\"Times New Roman\")\n",
    "ax1.legend(title='Child', title_fontsize=10, fontsize=8, loc='center left', bbox_to_anchor=(1.02, 0.5), prop={'family': 'Times New Roman'})\n",
    "\n",
    "# Panel (b): Colored by Stereotypy\n",
    "sns.scatterplot(\n",
    "    data=df_sampled,\n",
    "    x='UMAP3',\n",
    "    y='UMAP2',\n",
    "    hue='Label',\n",
    "    palette=color_map_label,\n",
    "    s=30,\n",
    "    alpha=0.6,\n",
    "    linewidth=0,\n",
    "    ax=ax2\n",
    ")\n",
    "ax2.set_title(\"2D UMAP Accelerometer Feature Space $PS_{1}$  – Colored by Stereotypy\", fontsize=14, family=\"Times New Roman\")\n",
    "ax2.set_xlabel(\"UMAP2\", fontsize=12, family=\"Times New Roman\")\n",
    "ax2.set_ylabel(\"UMAP3\", fontsize=12, family=\"Times New Roman\")\n",
    "ax2.set_xticks([]); ax2.set_yticks([])\n",
    "ax2.text(-0.1, 1.05, \"(b)\", transform=ax2.transAxes, fontsize=14, fontweight=\"bold\", family=\"Times New Roman\")\n",
    "ax2.legend(title='Class', title_fontsize=10, fontsize=9, prop={'family': 'Times New Roman'})\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig(\".pdf\", bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
